{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d381ae1-22d0-4b83-87ce-e90372c0eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef50a8ae-941d-4aad-9571-c27737f5ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install\n",
    "\n",
    "# !pip install kagglehub\n",
    "# !pip install opencv-python\n",
    "# !pip install transformers torch scikit-learn matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "816f5f11-2026-48f7-a109-cc33c7dd2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca3df169-d5e1-4948-84a2-9202baa11f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model, class, variables\n",
    "\n",
    "def load_images_from_folder(folder, image_size=(224, 224)):\n",
    "    images = []\n",
    "    image_files = []\n",
    "    i=-1\n",
    "    for filename in os.listdir(folder)[:1000]:\n",
    "        i+=1\n",
    "        if i%100==0: \n",
    "            print(i)\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "                img = img.resize(image_size)  # Resize for ViT input size\n",
    "                images.append(img)\n",
    "                image_files.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load image {filename}: {e}\")\n",
    "    return images, image_files\n",
    "\n",
    "def get_image_embeddings(images):\n",
    "    embeddings = []\n",
    "    for img in images:\n",
    "        inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Extract the [CLS] token as the image embedding\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    # Convert the list of arrays into a single numpy array\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def find_optimal_clusters(embeddings, max_clusters=10):\n",
    "    silhouette_scores = []\n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(embeddings)\n",
    "        silhouette_avg = silhouette_score(embeddings, cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        print(f\"Silhouette score for {n_clusters} clusters: {silhouette_avg}\")\n",
    "    # Select the number of clusters with the highest silhouette score\n",
    "    optimal_clusters = np.argmax(silhouette_scores) + 2\n",
    "    print(f\"Optimal number of clusters: {optimal_clusters}\")\n",
    "    return optimal_clusters\n",
    "\n",
    "def visualize_clusters(images, image_files, cluster_labels, n_samples=3):\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        if len(clusters[label]) < n_samples:\n",
    "            clusters[label].append(image_files[i])\n",
    "    \n",
    "    # Plot images from each cluster\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for cluster_id, img_files in clusters.items():\n",
    "        for i, img_file in enumerate(img_files):\n",
    "            img_path = os.path.join(image_folder, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            plt.subplot(len(clusters), n_samples, cluster_id * n_samples + i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Cluster {cluster_id}\")\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def get_image_embeddings_resnet(images):\n",
    "    embeddings = []\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    for img in images:\n",
    "        img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            outputs = resnet_model(img_tensor)\n",
    "        embedding = outputs.flatten().cpu().numpy()  # Flatten to a 1D array\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844a0c31-19ed-49f1-ad52-dcf1b9419314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ViT\n",
    "\n",
    "image_folder = 'inputs/mnist_test/'\n",
    "images, image_files = load_images_from_folder(image_folder)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "print(\"Generating embeddings for images...\")\n",
    "embeddings = get_image_embeddings(images)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "# optimal_clusters = find_optimal_clusters(embeddings)\n",
    "optimal_clusters = 10\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings)\n",
    "visualize_clusters(images, image_files, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef8390a-4524-4523-8066-050e8b54badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResNet\n",
    "\n",
    "image_folder = 'inputs/mnist_test/'\n",
    "images, image_files = load_images_from_folder(image_folder)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model = torch.nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "print(\"Generating embeddings using ResNet for images...\")\n",
    "embeddings = get_image_embeddings_resnet(images)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "optimal_clusters = 10\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings)\n",
    "visualize_clusters(images, image_files, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01c9d3bf-640c-4356-8a68-fca30fc4b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combined(ViT, ResNet)\n",
    "\n",
    "image_folder = 'inputs/mnist_test/'\n",
    "images, image_files = load_images_from_folder(image_folder)\n",
    "print(\"Generating embeddings using ViT for images...\")\n",
    "vit_embeddings = get_image_embeddings(images)  # Shape: (num_images, 768)\n",
    "print(\"ViT Embeddings shape:\", vit_embeddings.shape)\n",
    "print(\"Generating embeddings using ResNet for images...\")\n",
    "resnet_embeddings = get_image_embeddings_resnet(images)  # Shape: (num_images, 2048)\n",
    "print(\"ResNet Embeddings shape:\", resnet_embeddings.shape)\n",
    "combined_embeddings = np.hstack((vit_embeddings, resnet_embeddings))  # Shape: (num_images, 768 + 2048)\n",
    "print(\"Combined Embeddings shape:\", combined_embeddings.shape)\n",
    "print(\"Finding optimal clusters for combined embeddings...\")\n",
    "optimal_clusters = 10  # You can use find_optimal_clusters(combined_embeddings) if needed\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(combined_embeddings)\n",
    "print(\"Visualizing clusters for combined embeddings...\")\n",
    "visualize_clusters(images, image_files, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016df71a-1e98-457d-b04e-9cc82494196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "Generating embeddings using ViT for images...\n"
     ]
    }
   ],
   "source": [
    "## PCA(combined(ViT, ResNet))\n",
    "\n",
    "image_folder = 'inputs/mnist_test/'\n",
    "images, image_files = load_images_from_folder(image_folder)\n",
    "print(\"Generating embeddings using ViT for images...\")\n",
    "vit_embeddings = get_image_embeddings(images)  # Shape: (num_images, 768)\n",
    "print(\"ViT Embeddings shape:\", vit_embeddings.shape)\n",
    "print(\"Generating embeddings using ResNet for images...\")\n",
    "resnet_embeddings = get_image_embeddings_resnet(images)  # Shape: (num_images, 2048)\n",
    "print(\"ResNet Embeddings shape:\", resnet_embeddings.shape)\n",
    "combined_embeddings = np.hstack((vit_embeddings, resnet_embeddings))  # Shape: (num_images, 768 + 2048)\n",
    "print(\"Combined Embeddings shape:\", combined_embeddings.shape)\n",
    "print(\"Applying PCA to reduce to 10 principal components...\")\n",
    "pca = PCA(n_components=10)\n",
    "reduced_embeddings = pca.fit_transform(combined_embeddings)  # Shape: (num_images, 10)\n",
    "print(\"Reduced Embeddings shape:\", reduced_embeddings.shape)\n",
    "print(\"Finding optimal clusters for PCA-reduced embeddings...\")\n",
    "optimal_clusters = 10  # You can use find_optimal_clusters(reduced_embeddings) if needed\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(reduced_embeddings)\n",
    "print(\"Visualizing clusters for PCA-reduced embeddings...\")\n",
    "visualize_clusters(images, image_files, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663584e-8412-4ed6-b8bd-6073c425634d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001f0af-860c-4916-81f2-9195e47e571e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414041d-d18b-4c88-ac82-0db12b16696b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
